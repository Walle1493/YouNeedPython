{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "004de6046f1b3d314f33fdb43a2dc798b2646e5600efd8df5066c8b63a00ff6d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 情感分析"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.导入"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "import string"
   ]
  },
  {
   "source": [
    "## 2.分词"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 导入文本"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Nice quality, fairly quiet, nice looking and not too big.  I bought two.'"
   ]
  },
  {
   "source": [
    "#### 载入停用词"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "sw = stopwords.words(\"english\") + list(string.punctuation)\n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosostros', 'vosostras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
     ]
    }
   ],
   "source": [
    "# 西班牙语的停用词\n",
    "spanish_stopwords = stopwords.words(\"spanish\")\n",
    "print(spanish_stopwords)"
   ]
  },
  {
   "source": [
    "#### 分词"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['nice', 'quality', 'fairly', 'quiet', 'nice', 'looking', 'big', 'bought', 'two']\n"
     ]
    }
   ],
   "source": [
    "tokenize = [word for word in word_tokenize(str(text).lower()) if word not in sw]\n",
    "print(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Nice', 'quality', ',', 'fairly', 'quiet', ',', 'nice', 'looking', 'and', 'not', 'too', 'big', '.', 'I', 'bought', 'two', '.']\n"
     ]
    }
   ],
   "source": [
    "# 使用word_tokenize\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "source": [
    "## 3.计数、词性标签"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 词性标签"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('nice', 'JJ'), ('quality', 'NN'), ('fairly', 'RB'), ('quiet', 'JJ'), ('nice', 'JJ'), ('looking', 'VBG'), ('big', 'JJ'), ('bought', 'VBD'), ('two', 'CD')]\n"
     ]
    }
   ],
   "source": [
    "postag = nltk.pos_tag(tokenize)\n",
    "print(postag)"
   ]
  },
  {
   "source": [
    "#### 词频"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('nice', 'JJ'), ('quality', 'NN'), ('fairly', 'RB'), ('quiet', 'JJ'), ('looking', 'VBG'), ('big', 'JJ'), ('bought', 'VBD'), ('two', 'CD')]\n"
     ]
    }
   ],
   "source": [
    "freq = nltk.FreqDist(postag)\n",
    "print(list(freq))"
   ]
  },
  {
   "source": [
    "#### 按照词频排序"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(('nice', 'JJ'), 2), (('quality', 'NN'), 1), (('fairly', 'RB'), 1), (('quiet', 'JJ'), 1), (('looking', 'VBG'), 1), (('big', 'JJ'), 1), (('bought', 'VBD'), 1), (('two', 'CD'), 1)]\n"
     ]
    }
   ],
   "source": [
    "word_list = freq.most_common()\n",
    "print(word_list)"
   ]
  },
  {
   "source": [
    "#### 查看pos_tag的意思"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "source": [
    "#### 存入DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      word  pos  freq\n",
       "0     nice   JJ     2\n",
       "1  quality   NN     1\n",
       "2   fairly   RB     1\n",
       "3    quiet   JJ     1\n",
       "4  looking  VBG     1\n",
       "5      big   JJ     1\n",
       "6   bought  VBD     1\n",
       "7      two   CD     1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>pos</th>\n      <th>freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nice</td>\n      <td>JJ</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>quality</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fairly</td>\n      <td>RB</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>quiet</td>\n      <td>JJ</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>looking</td>\n      <td>VBG</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>big</td>\n      <td>JJ</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bought</td>\n      <td>VBD</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>two</td>\n      <td>CD</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "word_, pos_, freq_ = [], [], []\n",
    "\n",
    "for i in range(len(word_list)):\n",
    "    word_.append(word_list[i][0][0])\n",
    "    pos_.append(word_list[i][0][1])\n",
    "    freq_.append(word_list[i][1])\n",
    "\n",
    "df = pd.DataFrame({'word': word_, 'pos': pos_, 'freq': freq_}, columns=['word', 'pos', 'freq'])\n",
    "df"
   ]
  },
  {
   "source": [
    "## 计算单词得分"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 函数解读"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[SentiSynset('great.n.01'), SentiSynset('great.s.01'), SentiSynset('great.s.02'), SentiSynset('great.s.03'), SentiSynset('bang-up.s.01'), SentiSynset('capital.s.03'), SentiSynset('big.s.13')]\n"
     ]
    }
   ],
   "source": [
    "sentis = swn.senti_synsets(\"great\")\n",
    "print(list(sentis))"
   ]
  },
  {
   "source": [
    "#### 单词得分"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<great.s.02: PosScore=0.75 NegScore=0.0>'"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "str(swn.senti_synset('great.s.02'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.75\n0.625\n"
     ]
    }
   ],
   "source": [
    "# 积极得分\n",
    "print(swn.senti_synset('great.s.02').pos_score())\n",
    "# 消极得分\n",
    "print(swn.senti_synset(\"awful.s.02\").neg_score())"
   ]
  },
  {
   "source": [
    "#### 编码转换"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ['NN','NNP','NNPS','NNS','UH']\n",
    "v = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "a = ['JJ','JJR','JJS']\n",
    "r = ['RB','RBR','RBS','RP','WRB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['word'])):\n",
    "    z = df.iloc[i,1]\n",
    "    if z in n:\n",
    "        df.iloc[i,1]='n'\n",
    "    elif z in v:\n",
    "        df.iloc[i,1]='v'\n",
    "    elif z in a:\n",
    "        df.iloc[i,1]='a'\n",
    "    elif z in r:\n",
    "        df.iloc[i,1]='r'\n",
    "    else:\n",
    "        df.iloc[i,1]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      word pos  freq\n",
       "0     nice   a     2\n",
       "1  quality   n     1\n",
       "2   fairly   r     1\n",
       "3    quiet   a     1\n",
       "4  looking   v     1\n",
       "5      big   a     1\n",
       "6   bought   v     1\n",
       "7      two         1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>pos</th>\n      <th>freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nice</td>\n      <td>a</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>quality</td>\n      <td>n</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fairly</td>\n      <td>r</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>quiet</td>\n      <td>a</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>looking</td>\n      <td>v</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>big</td>\n      <td>a</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bought</td>\n      <td>v</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>two</td>\n      <td></td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "#### 计算总体得分"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in range(len(df['word'])):\n",
    "    # senti_synsets(word, pos)\n",
    "    m = list(swn.senti_synsets(df.iloc[i,0], df.iloc[i,1]))\n",
    "    s = 0\n",
    "    ra = 0\n",
    "    if len(m) > 0:\n",
    "        for j in range(len(m)):\n",
    "            s += (m[j].pos_score()-m[j].neg_score())/(j+1)\n",
    "            ra += 1/(j+1)\n",
    "        score.append(s/ra)\n",
    "    else:\n",
    "        score.append(0)\n",
    "new_df = pd.concat([df, pd.DataFrame({'score':score})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      word pos  freq     score\n",
       "0     nice   a     2  0.708942\n",
       "1  quality   n     1  0.352190\n",
       "2   fairly   r     1 -0.034091\n",
       "3    quiet   a     1 -0.218537\n",
       "4  looking   v     1  0.012092\n",
       "5      big   a     1  0.103294\n",
       "6   bought   v     1  0.083942\n",
       "7      two         1  0.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>pos</th>\n      <th>freq</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nice</td>\n      <td>a</td>\n      <td>2</td>\n      <td>0.708942</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>quality</td>\n      <td>n</td>\n      <td>1</td>\n      <td>0.352190</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fairly</td>\n      <td>r</td>\n      <td>1</td>\n      <td>-0.034091</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>quiet</td>\n      <td>a</td>\n      <td>1</td>\n      <td>-0.218537</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>looking</td>\n      <td>v</td>\n      <td>1</td>\n      <td>0.012092</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>big</td>\n      <td>a</td>\n      <td>1</td>\n      <td>0.103294</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bought</td>\n      <td>v</td>\n      <td>1</td>\n      <td>0.083942</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>two</td>\n      <td></td>\n      <td>1</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "source": [
    "# 规整代码"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "import string\n",
    "\n",
    "n = ['NN', 'NNP', 'NNPS', 'NNS', 'UH']\n",
    "v = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "a = ['JJ', 'JJR', 'JJS']\n",
    "r = ['RB', 'RBR', 'RBS', 'RP', 'WRB']\n",
    "\n",
    "\n",
    "def calculate_sentiment(text):\n",
    "    sw = stopwords.words(\"english\") + list(string.punctuation)\n",
    "    tokenize = [word for word in word_tokenize(str(text).lower()) if word not in sw]\n",
    "    postag = nltk.pos_tag(tokenize)\n",
    "    freq = nltk.FreqDist(postag)\n",
    "    word_list = freq.most_common()\n",
    "\n",
    "    word_, pos_, freq_ = [], [], []\n",
    "    for i in range(len(word_list)):\n",
    "        word_.append(word_list[i][0][0])\n",
    "        pos_.append(word_list[i][0][1])\n",
    "        freq_.append(word_list[i][1])\n",
    "    df = pd.DataFrame({'word': word_, 'pos': pos_, 'freq': freq_}, columns=['word', 'pos', 'freq'])\n",
    "\n",
    "    for i in range(len(df['word'])):\n",
    "        z = df.iloc[i, 1]\n",
    "        if z in n:\n",
    "            df.iloc[i, 1] = 'n'\n",
    "        elif z in v:\n",
    "            df.iloc[i, 1] = 'v'\n",
    "        elif z in a:\n",
    "            df.iloc[i, 1] = 'a'\n",
    "        elif z in r:\n",
    "            df.iloc[i, 1] = 'r'\n",
    "        else:\n",
    "            df.iloc[i, 1] = ''\n",
    "\n",
    "    score = []\n",
    "    for i in range(len(df['word'])):\n",
    "        m = list(swn.senti_synsets(df.iloc[i, 0], df.iloc[i, 1]))\n",
    "        \n",
    "        s = 0\n",
    "        ra = 0\n",
    "        if len(m) > 0:\n",
    "            for j in range(len(m)):\n",
    "                s += (m[j].pos_score() - m[j].neg_score()) / (j + 1)\n",
    "                ra += 1 / (j + 1)\n",
    "            score.append(s / ra)\n",
    "        else:\n",
    "            score.append(0)\n",
    "    new_df = pd.concat([df, pd.DataFrame({'score': score})], axis=1)\n",
    "\n",
    "    score_sum = np.sum(new_df[\"score\"])\n",
    "    if score_sum > 0:\n",
    "        attitude = \"positive\"\n",
    "    else:\n",
    "        attitude = \"negative\"\n",
    "\n",
    "    return attitude, score_sum"
   ]
  },
  {
   "source": [
    "## 影评分析"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = [\n",
    "    \"\"\"It might have been an error on Disney's part to release only the first 2 episodes at once instead of 4 episodes. While I am on of the few people who absolutely loved the intrigue and mystery of the first three episodes, this exceptional show has been getting a lot of hate due to a lack of plot.\n",
    "... And then the 4th episode came out. Not only was it an exceptional episode, but it justified the use of the first three and even gave some answers to the many questions of Wanda vision.\n",
    "Overall a brilliant show that shouldn't be judged on the first three episodes (especially if your only complaint is a lack of plot)\"\"\",\n",
    "    \"\"\"Q1: Would you lie to the police and falsely accuse your best friend's father of child abuse so that your best friend could run away for a couple of days to see their SO?\n",
    "    Q2: Would you throw your purse (assuming you have one) in a river and break your cell phone in order to pretend to be pushed off a bridge by your best friend to play a joke on your parents?\n",
    "    Q3: Would you scream at your parents and yell you were a terrible person and you killed your best friend because of your Dad when you knew this was a prank all along?\n",
    "    If your answers to all of these are \"yes\", this might be the movie for you.\"\"\",\n",
    "    \"\"\"Only real reason I'm writing this is to counter everyone else's reviews absurdly angry reviews. This was a decent story, well acted and no I didn't know where it was going. I went along with the ride. People are mad at the plot that the parents did stupid things... well people do stupid things. Isn't that the point? Also, if a movie inspired a reaction from you... isn't that also the point?\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['positive', 'positive', 'positive']\n"
     ]
    }
   ],
   "source": [
    "review = [calculate_sentiment(t)[0] for t in imdb]\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}